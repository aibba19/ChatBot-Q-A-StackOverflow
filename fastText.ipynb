{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac5faa6-954b-4e58-abc1-79f3a18f6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b76e7b-1f54-42cd-a68c-2ced2223a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dopo il caricamento del file, si procede a creare un file apposito in cui vi sono sono i titoli\n",
    "(già processati) con le rispettive label (create mediante coni rispettivi tag)\n",
    "'''\n",
    "\n",
    "data = pd.read_csv('DB/Preprocessed_data.csv')\n",
    "\n",
    "data = data[data['tags'].notna()]\n",
    "data = data[data['processed_title'].notna()]\n",
    "\n",
    "\n",
    "\n",
    "tmp_tags = []\n",
    "tmp_titles = []\n",
    " \n",
    "for tags in data[\"tags\"]:\n",
    "    \n",
    "    tmp_tags.append(tags)\n",
    "\n",
    "for titles in data[\"processed_title\"]:\n",
    "    \n",
    "    tmp_titles.append(titles)\n",
    "\n",
    "#print(tmp_tags)\n",
    "#print(tmp_titles)\n",
    "       \n",
    "i = 0\n",
    "tmp_label = []\n",
    "final = []\n",
    "while(i < len(data)):\n",
    "    \n",
    "    #Controllo se la domanda ha un solo tag\n",
    "    if(len(tmp_tags[i].split('|')) == 1):\n",
    "        \n",
    "            tmp_label = \"__label__\" + tmp_tags[i].split('|')[0] + \" \" + tmp_titles[i]\n",
    "            \n",
    "    #Controllo se la domanda ha almeno due tag\n",
    "    if(len(tmp_tags[i].split('|')) > 1):\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        while(j < len(tmp_tags[i].split('|'))):\n",
    "            \n",
    "            #Controllo se è la prima-esima iterazione (analisi del primo tag)\n",
    "            if ( j == 0):\n",
    "                tmp_label = \"__label__\" + tmp_tags[i].split('|')[j] + \" \" + tmp_titles[i]\n",
    "                j = j+1\n",
    "                \n",
    "            #Controllo se è la seconda-esami iterazione (analisi dal secondo tag)\n",
    "            else:\n",
    "                tmp_label = \" __label__\" + tmp_tags[i].split('|')[j] + \" \" + tmp_label\n",
    "                j = j+1\n",
    "                \n",
    "    final.append(tmp_label)\n",
    "    i = i+1\n",
    "\n",
    "#print(\"------------\")\n",
    "#print(final)\n",
    "#Creo df per il training formato da tags + processed title \n",
    "#__label__ processed_title\n",
    "df = pd.DataFrame(final)\n",
    "\n",
    "train, valid = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train.to_csv('DB/fasttext.train')\n",
    "valid.to_csv('DB/fasttext.valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b88502a-f8d1-4065-8088-b968eebf3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Qui si procede all'allenamento del modello.\n",
    "\n",
    "Come primo step, dopo aver controllato la grandezza del file, bisogna dividere in due il file con le label ('GFG.csv'):\n",
    "\n",
    "\t>> wc GFG.csv\n",
    "\t\t15404  169582 1401900 GFG.csv    #CONTIENE 15404 ESEMPI\n",
    "\n",
    "\t>> head -n 12404 GFG.csv > stack.train\n",
    "    >> tail -n 3000 GFG.csv > stack.valid\n",
    "\n",
    "Successivamente, si può passare all'addastramento del modello.\n",
    "\n",
    "L'utilizzo del parametro \"lr\" permette di modificare la velocità di apprendimento del modello.\n",
    "L'aumento (o la diminuzione) della volecità di apprendimento dell'algoritmo permette di far si che il modello\n",
    "cambi dopo l'elaborazione di ciascun esempio.\n",
    "Con un tasso di apprendimento pari a 0, si ha che il modello non cambia e quindi non apprende nulla, mentre\n",
    "si hanno dei buoni valori di tasso di apprendimento nell'intervallo 0.1 - 1.0\n",
    "\n",
    "L'utilizzo del parametro \"epoch\" permette di avere un maggiore tasso di apprendimento.\n",
    "Dato che, in base ad un impostazione predefinita di fastText, esso vede ogni esempio di allenamento\n",
    "solo 5 volte durante l'addestramento (numero molto piccolo dato che non abbiamo solo ... esempi di addestramento),\n",
    "si può aumentare il numero di volte in cui viene visualizzato ogni esempio (noto anche numero di epoche)\n",
    "utilizzando il paramento \"epoch\".\n",
    "\n",
    "L'utilizzo del parametro \"wordNgrams\" permette di migliorare le prestazioni del modello. \n",
    "Piuttosto che utilizzare solo gli unigrammi,si vanno ad utilizzare i bigrammi di parole,\n",
    "poichè l'ordine delle parole è importante.\n",
    "Nel fastText, con \"unigramma\" ci si riferisce ad una singola parola.\n",
    "Nel fastText, con \"bigrammi\" ci si riferisce a due parole consecutive.\n",
    "'''\n",
    "\n",
    "model = fasttext.train_supervised(input='DB/fasttext.train', lr=0.8, epoch=40, wordNgrams=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53abff4-3025-4c20-8aa6-ef7bd1496bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18207, 0.817048387982644, 0.29705065995726754)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test('DB/fasttext.valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61393bbb-253b-4625-86a9-2633c499923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"DB/model_stack.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f2ce9f-5042-4124-a629-a72e217b7d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__pip',\n",
       "  '__label__django',\n",
       "  '__label__installation',\n",
       "  '__label__virtualenv',\n",
       "  '__label__linux',\n",
       "  '__label__macos',\n",
       "  '__label__ubuntu',\n",
       "  '__label__pandas',\n",
       "  '__label__centos'),\n",
       " array([0.14572966, 0.12606479, 0.02434609, 0.02118622, 0.01620425,\n",
       "        0.01179107, 0.01125851, 0.01040747, 0.0103855 ]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"os using python installed default install reason asking use yum install going install mysqlpython client version python installed os centos installed manually using altinstall option python mysqlpython likley installed default version python machine go see mysqlpython need either install using easyinstall pip download mysqlpython package manually install add ever installed python path search mysqlpython machine see installed give better understanding going\",k=-1,threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e170e7-3419-4e3f-875a-34dc367a8cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__csv',\n",
       "  '__label__url',\n",
       "  '__label__encoding',\n",
       "  '__label__pandas',\n",
       "  '__label__utf-8'),\n",
       " array([0.78492862, 0.02154011, 0.01472156, 0.01181447, 0.01141658]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"problem loading compressed gz csv file url \", k=-1, threshold= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f95f32-af50-494d-9d8d-99416546d429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
