{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63621f6d-38f9-4812-a414-70a6168ffc98",
   "metadata": {},
   "source": [
    "<h1>Get results functions</h1>\n",
    "\n",
    "In this file we define the results function for both tecnologies that calculates the most similar records to the user input in our data and return it to the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87554b71-30d9-46ae-8601-bbdff479dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "%run create_embeddings.ipynb\n",
    "import preprocessing\n",
    "import tfidf\n",
    "import scipy\n",
    "#pd.set_option('max_colwidth', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dab04f-cdbb-48f2-b7f5-cb3f6bacf29d",
   "metadata": {},
   "source": [
    "<h2>Import data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed60d8-463a-4b47-9f00-8b8ff5c28e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data on Stack Overflow DB already preprocessed\n",
    "data_stack = pd.read_csv('DB/Preprocessed_data.csv')\n",
    "data_stack.set_index('id', inplace=True)\n",
    "\n",
    "#Create the data to return results for tfidf\n",
    "data_stack_tfidf = data_stack.dropna()\n",
    "\n",
    "data_stack = data_stack[data_stack['processed_title'].notna()]\n",
    "\n",
    "#Data on Ontology DB already preprocessed\n",
    "data_onto = pd.read_csv('DB/Preprocessed_ontology.csv')\n",
    "\n",
    "#Matrix for stack tfidf processing \n",
    "stack_corpus = data_stack['processed_title'] + data_stack['questions_processed'] + data_stack['answers_processed'] \n",
    "stack_corpus = stack_corpus.dropna()\n",
    "\n",
    "#Matrix for ontology tfidf processing\n",
    "onto_corpus = data_onto.description_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497782e1-f9ce-4ec9-a3c1-5505b070c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import word to vec model \n",
    "word_2_vec_model = gensim.models.word2vec.Word2Vec.load('DB/word2vec_trained.bin')\n",
    "word_2_vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1e41e-af12-4907-aae0-82a557d661e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion to clear raw txt \n",
    "def normalize(txt):\n",
    "    phrase = preprocessing.clear_text(txt)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33943de7-eb61-4606-ad91-5fa6de5dc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import title embeddings \n",
    "embeddings = pd.read_csv('DB/titleEmbeddings.csv')\n",
    "\n",
    "idList = embeddings['id']\n",
    "embeddings = embeddings.drop(columns = ['id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d795062-355c-4fff-b582-17127cb2cd27",
   "metadata": {},
   "source": [
    "<h2>Word to vec results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02874628-8efd-4f71-855b-b3f05f95023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate cosine similarity between user raw txt and stack overflow processed title with word to vec \n",
    "\n",
    "def w2v_stack_result(txt):\n",
    "    stringSearch = normalize(txt)\n",
    "\n",
    "    numberResult = 5\n",
    "\n",
    "    #Vectorize user query\n",
    "    vectorSearch = np.array([questionToVec(stringSearch, word_2_vec_model)])\n",
    "    \n",
    "    #Load embeddings \n",
    "    allTitleEmb = embeddings.values\n",
    "\n",
    "    #Cosine similarity between titles and user query vectorized\n",
    "    similarityCosine = pd.Series(cosine_similarity(vectorSearch, allTitleEmb)[0])\n",
    "    \n",
    "    #Lista che conterrà coppie i,j con i indice e j score di similarità\n",
    "    results = []\n",
    "    \n",
    "    #Una volta calcolati gli score di similarità rendo i 10 più alti\n",
    "    for i,similiarity_score in similarityCosine.nlargest(numberResult).iteritems():\n",
    "        #Filtro i tag da rendere come risultato, eliminando quelli che sono già presenti nella string search per facilitare prossimi passaggi \n",
    "        idResults = idList[i]\n",
    "        tags = data_stack.loc[idResults].tags.split('|')\n",
    "        stack_id = idResults\n",
    "        stack_title = data_stack.loc[idResults].title\n",
    "        \n",
    "        results.append(tuple([stack_id, similiarity_score, tags, stack_title ]))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3ed64-f52a-455b-8c44-1ffddf9ff6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to calculate cosine similarity between raw txt and function description of ontology with word to vec \n",
    "def w2v_ontology_result(txt):\n",
    "    stringSearch = normalize(txt)\n",
    "\n",
    "    #print(stringSearch)\n",
    "\n",
    "    numberResult = 3\n",
    "\n",
    "    #Viene vettorizzata la query dell'utente\n",
    "\n",
    "    vectorSearch = np.array([questionToVec(stringSearch, word_2_vec_model)])\n",
    "    \n",
    "    #Carico il file con gli embeddings dei titoli sui quali effettuare la corrispondenza\n",
    "    allFuncEmb = pd.read_csv('DB/functionEmbeddings.csv').values\n",
    "\n",
    "    #Calcolo della similarità del coseno for le query e tutti i titoli\n",
    "\n",
    "    similarityCosine = pd.Series(cosine_similarity(vectorSearch, allFuncEmb)[0])\n",
    "    \n",
    "    #Lista che conterrà coppie i,j con i indice e j score di similarità\n",
    "    results = []\n",
    "    \n",
    "      \n",
    "    #Una volta calcolati gli score di similarità rendo i 10 più alti\n",
    "    for i,similiarity_score in similarityCosine.nlargest(numberResult).iteritems():\n",
    "        #print(i, data.Body[i])\n",
    "        #Filtro i tag da rendere come risultato, eliminando quelli che sono già presenti nella string search per facilitare prossimi passaggi \n",
    "        description = data_onto.iloc[[i]].description.item()\n",
    "        function = data_onto.iloc[[i]].function.item()\n",
    "                    \n",
    "        results.append(tuple([function,description, similiarity_score]))\n",
    "      \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d17bb-4eed-41c7-b23e-bcd7c9cee857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate cosine similarity between user raw txt and stack overflow processed title with tf-idf \n",
    "def tfidf_stack_result(txt):\n",
    "    \n",
    "    stringSearch = normalize(txt)\n",
    "    related_docs_indices,similarity_values = tfidf.get_results(stack_corpus, stringSearch)\n",
    "    \n",
    "    results = []\n",
    "    i = 0 \n",
    "    \n",
    "    for idx in related_docs_indices:\n",
    "        \n",
    "        stack_id = data_stack_tfidf.iloc[idx].name\n",
    "        stack_title = data_stack_tfidf.iloc[idx].title\n",
    "        tags = data_stack_tfidf.iloc[idx].tags.split('|')\n",
    "        sim_value = similarity_values[i]\n",
    "        \n",
    "        i = i+1\n",
    "        \n",
    "        results.append(tuple([stack_id, sim_value, tags, stack_title ]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38925c8b-cad5-48b8-a097-8363d0811d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate cosine similarity between user raw txt and stack overflow processed title with tf-idf \n",
    "def tfidf_onto_result(txt):\n",
    "    stringSearch = normalize(txt)\n",
    "    related_docs_indices,similarity_values = tfidf.get_results(onto_corpus, stringSearch)\n",
    "    \n",
    "    results = []\n",
    "    i=0\n",
    "    \n",
    "    for idx in related_docs_indices:\n",
    "        \n",
    "        description = data_onto.iloc[[idx]].description.item()\n",
    "        function = data_onto.iloc[[idx]].function.item()\n",
    "        sim_value = similarity_values[i]\n",
    "        \n",
    "        i = i+1\n",
    "        \n",
    "        results.append(tuple([function,description, sim_value]))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30077129-b9eb-4bca-bc5a-f1f6e0026517",
   "metadata": {},
   "source": [
    "Example results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2650c127-f26a-4775-a6fc-4aaf2a2a3584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(52303121, 0.7828488355884394, ['csv', 'geocode'], 'CSV uploading issue'),\n",
       " (45473164,\n",
       "  0.7819319109892543,\n",
       "  ['csv', 'neo4j', 'cypher'],\n",
       "  'Loading Data from CSV to Neo4j'),\n",
       " (51687602,\n",
       "  0.7669548453682289,\n",
       "  ['numpy'],\n",
       "  'issue when loading a data file with numpy'),\n",
       " (30718958,\n",
       "  0.7659812488548408,\n",
       "  ['csv'],\n",
       "  'Issue with Outputting data from CSV File'),\n",
       " (62863078,\n",
       "  0.7638483273148219,\n",
       "  ['pandas'],\n",
       "  'Problem loading a compressed (.gz) .csv file from url')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_stack_result('problem loading csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c31f3264-2124-44bc-b676-9705b31bafae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49044952 0.4693495  0.46120036 0.4378283 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(17673314,\n",
       "  0.4904495215566453,\n",
       "  ['mysql', 'datetime'],\n",
       "  'Date Time convert from CSV to MySQL'),\n",
       " (68513445,\n",
       "  0.4693494967501211,\n",
       "  ['pandas', 'dataframe', 'csv', 'export-to-csv'],\n",
       "  'Append Pandas dataframe to top of csv file without loading csv file content'),\n",
       " (56635383,\n",
       "  0.46120035712587226,\n",
       "  ['csv'],\n",
       "  'Compare two CSV files and create a new CSV'),\n",
       " (29016807,\n",
       "  0.43782829543979157,\n",
       "  ['file', 'csv', 'import-from-csv'],\n",
       "  'CSV file based on other files data')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_stack_result('problem loading csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b11560e1-951b-49e2-b9e2-2191b006c231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('javax.management.monitor.CounterMonitorMBean-getNotify()',\n",
       "  \"Gets the notification's on/off switch value.   \",\n",
       "  0.4709165875675452),\n",
       " ('javax.management.monitor.StringMonitorMBean-getNotifyMatch()',\n",
       "  \"Gets the matching notification's on/off switch value.   \",\n",
       "  0.3967464503165317),\n",
       " ('javax.management.monitor.GaugeMonitorMBean-getNotifyLow()',\n",
       "  \"Gets the low notification's on/off switch value.   \",\n",
       "  0.3878863765875934),\n",
       " ('javax.management.monitor.GaugeMonitorMBean-getNotifyHigh()',\n",
       "  \"Gets the high notification's on/off switch value.   \",\n",
       "  0.38516534840187544)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_onto_result('How to switch axes in matplotlib?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1abb2168-0a00-4df3-9594-717eca1f33d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32840468,\n",
       "  0.9165012689195305,\n",
       "  ['list'],\n",
       "  'combining list of list to single list Python'),\n",
       " (53249949,\n",
       "  0.9130771175085204,\n",
       "  ['list', 'zip', 'tuples'],\n",
       "  'How to combine a string list with a list of lists of integers'),\n",
       " (67668893,\n",
       "  0.9116054752341257,\n",
       "  ['list', 'numpy'],\n",
       "  'How to change two separate list of list to single list of list?'),\n",
       " (64295178,\n",
       "  0.9079844119741829,\n",
       "  ['list'],\n",
       "  'Appending list to a list does not generate list of lists'),\n",
       " (38604805, 0.9056062631734002, ['list'], 'Convert list into list of lists')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_stack_result('combine list of list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afd608-df9b-4d62-9000-37472d093316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
