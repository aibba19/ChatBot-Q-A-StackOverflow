{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5faa6-954b-4e58-abc1-79f3a18f6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import spacy\n",
    "%run calculateSentence.ipynb\n",
    "import preprocessing\n",
    "pd.set_option('max_colwidth', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026a9d6-2c7f-4dfc-873e-4409149f3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importazione DB\n",
    "\n",
    "data = pd.read_csv('DB/Preprocessed_data.csv')\n",
    "\n",
    "data = data[data['processed_title'].notna()]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a184d7-8cea-47c4-bbac-a681f0938b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importazione WordEmbeddings\n",
    "\n",
    "word_2_vec_model = gensim.models.word2vec.Word2Vec.load('DB/word2vec_trained.bin')\n",
    "word_2_vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fdb887-2fec-4917-9786-c3d7717e6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(words):\n",
    "    words = preprocessing.clear_text(words,\"w2v\")\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4750d1f9-4230-4554-88c5-7d542efa03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_result(txt, tag):\n",
    "    stringSearch = normalize(txt)\n",
    "\n",
    "    #print(stringSearch)\n",
    "\n",
    "    numberResult = \"10\"\n",
    "\n",
    "    #Viene vettorizzata la query dell'utente\n",
    "\n",
    "    vectorSearch = np.array([questionToVec(stringSearch, word_2_vec_model)])\n",
    "    \n",
    "    #Carico il file con gli embeddings dei titoli sui quali effettuare la corrispondenza\n",
    "    allTitleEmb = pd.read_csv('DB/titleEmbeddings.csv').values\n",
    "\n",
    "    #Calcolo della similarità del coseno for le query e tutti i titoli\n",
    "\n",
    "    similarityCosine = pd.Series(cosine_similarity(vectorSearch, allTitleEmb)[0])\n",
    "    \n",
    "    #Personalizzazione della misura di similarità\n",
    "\n",
    "    #similarityCosine = similarityCosine*(1+0.4*data.overall_scores_norm + 0.1*(data.sentiment_polarity))\n",
    "    similarityCosine = similarityCosine*(1+0.4*data.score)\n",
    "    \n",
    "    #Lista che conterrà coppie i,j con i indice e j score di similarità\n",
    "    results = []\n",
    "    tmp = 0 \n",
    "    \n",
    "    #Se tag è null vuol dire che siamo alla prima iterazione e non dobbiamo filtrare su nessun tag\n",
    "    if tag == None :   \n",
    "        #Una volta calcolati gli score di similarità rendo i 10 più alti\n",
    "        for i,j in similarityCosine.nlargest(int(numberResult)).iteritems():\n",
    "            #print(i, data.Body[i])\n",
    "            #Filtro i tag da rendere come risultato, eliminando quelli che sono già presenti nella string search per facilitare prossimi passaggi \n",
    "            tags = data.iloc[[i]].tags.item().split('|')\n",
    "            #print(tags)\n",
    "            for t in tags:\n",
    "                if t in stringSearch:\n",
    "                    tags.remove(t)\n",
    "                    \n",
    "            results.append(tuple([data.iloc[[i]].id.values[0], j, tags]))\n",
    "            print(results[tmp])\n",
    "            tmp = tmp+1\n",
    "    #Entriamo nell'else se abbiamo il tag che deve essere incluso nei nostri risultati, \n",
    "    #e eliminiamo i record che non lo contengono dai result \n",
    "    else : \n",
    "        \n",
    "        for i,j in similarityCosine.nlargest(int(numberResult)).iteritems():\n",
    "            \n",
    "            if tag in data.iloc[[i]].tags:\n",
    "                results.append(tuple([data.iloc[[i]].id.values[0], j, data.iloc[[i]].tags]))\n",
    "                print(results[tmp])\n",
    "                tmp = tmp+1\n",
    "            \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d75c7f-986c-4b17-bdd2-2c04e58ce5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_result('problem loading csv',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1faa0c-b453-4fdc-a91f-2ef3811804c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[95375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadf5aa-3a9d-4a4e-9a75-1c96c6f89276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
